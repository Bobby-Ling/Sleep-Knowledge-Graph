# 项目说明

## 项目结构

```
.
├── assets get_symptoms得到的json文件, 死数据
├── cypher_parsed cypher_normalizer.py得到的语句, toml目录是结构化数据, 可供neo4j_import.py导入
├── cyphers gpt生成的语句按照文件合并之后的, 需要cypher_normalizer.py处理才能导入
├── data 后端数据目录
├── dataset preprocess.py的输出和cypher_normalizer.py的输入
├── dataset-origin 预处理好的markdown和txt
├── scale_schemas 问卷元数据
├── analyze_scale.py 多问卷结果分析, naive版本, 示例参考__main__
├── backend.py 后端
├── cypher_normalizer.py    输入: dataset的toml文件
                            输出: cypher_parsed目录
├── dataset.csv 
├── langchain_demo.py   带历史记录的langchain demo
├── neo4j_import.py 输入: cypher_parsed/toml
                    输出: 导入数据库
├── parse_dataset.py
├── parse_patient_profiles.py
├── preprocess.py   输入: dataset-origin/knowledges(markdown文件) 
                    输出: dataset(分块好的markdown文件)
├── process.py  输入: dataset目录的分块后markdown
                输出: dataset目录的toml/json以及cypher目录的语句
├── prompts_template.py GPT模板
├── scale_dataset.py
├── scale_result.csv 问卷结果, 每个维度为整个问卷的总分(PSQI有特殊处理, 不太好, 要改)
```

## 数据库建立流程

1. preprocess.py
2. process.py
3. cypher_normalizer.py
4. neo4j_import.py(会运行`MATCH (n) DETACH DELETE n;`, 可注释掉)
5. 让GPT根据已有症状生成assets/symptoms.json
